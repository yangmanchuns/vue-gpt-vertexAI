// server/index.js
import dotenv from "dotenv";
dotenv.config();

import express from "express";
import { WebSocketServer } from "ws";
import { GoogleGenerativeAI } from "@google/generative-ai";

const app = express();
const port = process.env.PORT || 3001;

app.use(express.json());

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// HTTP ì„œë²„ ìƒì„±
const server = app.listen(port, () => {
  console.log("ğŸš€ Server started on port", port);
});

// WebSocket ì„œë²„ ìƒì„±
const wss = new WebSocketServer({ server });

wss.on("connection", (ws) => {
  console.log("ğŸ”¥ WebSocket í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨");

  // ğŸ¯ ê° í´ë¼ì´ì–¸íŠ¸ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬
  // Geminiì— ê·¸ëŒ€ë¡œ ë„˜ê¸¸ êµ¬ì¡°ë¡œ ìœ ì§€
  let history = [];

  ws.on("message", async (raw) => {
    let msg;

    // 1) JSONì¸ì§€ ì‹œë„ â†’ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ í…ìŠ¤íŠ¸ë¡œ ì·¨ê¸‰
    try {
      msg = JSON.parse(raw.toString());
    } catch {
      msg = { type: "text", data: raw.toString() };
    }

    console.log("ğŸ“Œ ìˆ˜ì‹  íƒ€ì…:", msg.type);

    // ê³µí†µ: ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash-lite" });

    // ------------------------------
    // 1) í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
    // ------------------------------
    if (msg.type === "text") {
      // íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
      history.push({
        role: "user",
        parts: [{ text: msg.data }]
      });

      try {
        const result = await model.generateContentStream({
          contents: history   // ğŸ‘‰ ì „ì²´ íˆìŠ¤í† ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€
        });

        let assistantReply = "";

        for await (const chunk of result.stream) {
          const text = chunk?.text();
          if (text) {
            ws.send(text);
            assistantReply += text;
          }
        }

        ws.send("[[END]]");

        // AI ì‘ë‹µë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
        history.push({
          role: "model",
          parts: [{ text: assistantReply }]
        });

      } catch (e) {
        console.error(e);
        ws.send("[[ERROR]]");
      }

      return;
    }

    // ------------------------------
    // 2) ì´ë¯¸ì§€ ë©”ì‹œì§€ ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)
    // ------------------------------
    if (msg.type === "image") {
      const visionModel = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

      // ìœ ì €ê°€ ì´ë¯¸ì§€ë¥¼ ë³´ëƒˆë‹¤ëŠ” ì •ë³´ë§Œ historyì— ë„£ìŒ
      history.push({
        role: "user",
        parts: [{ text: "ì´ë¯¸ì§€ ì—…ë¡œë“œ: " }, {
          inlineData: {
            mimeType: "image/png",
            data: msg.data.split(",")[1]  // dataURL ê¸°ì¤€
          }
        }]
      });

      try {
        const result = await visionModel.generateContentStream({
          contents: history
        });

        let assistantReply = "";

        for await (const chunk of result.stream) {
          const text = chunk?.text();
          if (text) {
            ws.send(text);
            assistantReply += text;
          }
        }

        ws.send("[[END]]");

        history.push({
          role: "model",
          parts: [{ text: assistantReply }]
        });

      } catch (e) {
        console.error(e);
        ws.send("[[ERROR]]");
      }

      return;
    }

    // ------------------------------
    // 3) ì—‘ì…€ HTML í…Œì´ë¸”
    // ------------------------------
    if (msg.type === "excel") {
      const cleanText = msg.data
        .replace(/<\/td><td>/g, " | ")
        .replace(/<\/tr>/g, "\n")
        .replace(/<[^>]+>/g, "");

      const promptText = "ì•„ë˜ì˜ í‘œ ë°ì´í„°ë¥¼ ê¸°ì–µí•˜ê³ , ì´í›„ ì§ˆë¬¸ì— ì´ í…Œì´ë¸” ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\n\n" + cleanText;

      history.push({
        role: "user",
        parts: [{ text: promptText }]
      });

      try {
        const result = await model.generateContentStream({
          contents: history
        });

        let assistantReply = "";

        for await (const chunk of result.stream) {
          const text = chunk?.text();
          if (text) {
            ws.send(text);
            assistantReply += text;
          }
        }

        ws.send("[[END]]");

        history.push({
          role: "model",
          parts: [{ text: assistantReply }]
        });

      } catch (e) {
        console.error(e);
        ws.send("[[ERROR]]");
      }

      return;
    }

    // ------------------------------
    // 4) ì—‘ì…€ TSV ë°ì´í„° (ì—‘ì…€ì—ì„œ ì§ì ‘ ë³µì‚¬í•œ í…ìŠ¤íŠ¸)
    // ------------------------------
    if (msg.type === "excel-tsv") {
      const promptText = "ì•„ë˜ì˜ ì—‘ì…€(íƒ­ êµ¬ë¶„) ë°ì´í„°ë¥¼ ê¸°ì–µí•˜ê³ , ì´í›„ ì§ˆë¬¸ì— ì´ í…Œì´ë¸” ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\n\n" + msg.data;

      history.push({
        role: "user",
        parts: [{ text: promptText }]
      });

      try {
        const result = await model.generateContentStream({
          contents: history
        });

        let assistantReply = "";

        for await (const chunk of result.stream) {
          const text = chunk?.text();
          if (text) {
            ws.send(text);
            assistantReply += text;
          }
        }

        ws.send("[[END]]");

        history.push({
          role: "model",
          parts: [{ text: assistantReply }]
        });

      } catch (e) {
        console.error(e);
        ws.send("[[ERROR]]");
      }

      return;
    }

  });
});
